{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.functions import to_timestamp,col,when\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read Metadata and Define Schema\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define metadata\n",
    "metadata = {\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"SaleID\",\n",
    "            \"nullable\": True,\n",
    "            \"type\": \"integer\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Contact\",\n",
    "            \"nullable\": True,\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Sex\",\n",
    "            \"nullable\": True,\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Age\",\n",
    "            \"nullable\": True,\n",
    "            \"type\": \"integer\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"State\",\n",
    "            \"nullable\": True,\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ProductID\",\n",
    "            \"nullable\": True,\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ProductType\",\n",
    "            \"nullable\": True,\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"SalePrice\",\n",
    "            \"nullable\": True,\n",
    "            \"type\": \"float\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Profit\",\n",
    "            \"nullable\": True,\n",
    "            \"type\": \"float\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Lead\",\n",
    "            \"nullable\": True,\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Month\",\n",
    "            \"nullable\": True,\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Year\",\n",
    "            \"nullable\": True,\n",
    "            \"type\": \"integer\"\n",
    "        }\n",
    "    ],\n",
    "    \"type\": \"struct\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to convert metadata to Spark StructType\n",
    "def convert_metadata_to_schema(metadata):\n",
    "    fields = []\n",
    "    for field in metadata['fields']:\n",
    "        if field['type'] == 'integer':\n",
    "            data_type = IntegerType()\n",
    "        elif field['type'] == 'string':\n",
    "            data_type = StringType()\n",
    "        elif field['type'] == 'float':\n",
    "            data_type = FloatType()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported type: {field['type']}\")\n",
    "        \n",
    "        fields.append(StructField(field['name'], data_type, field['nullable']))\n",
    "    \n",
    "    return StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert metadata to schema\n",
    "schema = convert_metadata_to_schema(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample data path (replace with your actual data path)\n",
    "data_path = \"data\\computer_sales.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/jovyan\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File not found: C:\\Users\\Indah Permata\\OneDrive\\Documents\\BOOTHCAMP DE\\dibimbing_spark_airflow\\data\\computer_sales.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Check if file exists\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(data_path):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File not found: C:\\Users\\Indah Permata\\OneDrive\\Documents\\BOOTHCAMP DE\\dibimbing_spark_airflow\\data\\computer_sales.csv"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "import os\n",
    "\n",
    "# Check working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# File path\n",
    "data_path = r\"C:\\Users\\Indah Permata\\OneDrive\\Documents\\BOOTHCAMP DE\\dibimbing_spark_airflow\\data\\computer_sales.csv\"\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(f\"File not found: {data_path}\")\n",
    "else:\n",
    "    print(f\"File found: {data_path}\")\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read Metadata and Define Schema\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"SaleID\", IntegerType(), True),\n",
    "    StructField(\"Contact\", StringType(), True),\n",
    "    StructField(\"Sex\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"State\", StringType(), True),\n",
    "    StructField(\"ProductID\", StringType(), True),\n",
    "    StructField(\"ProductType\", StringType(), True),\n",
    "    StructField(\"SalePrice\", FloatType(), True),\n",
    "    StructField(\"Profit\", FloatType(), True),\n",
    "    StructField(\"Lead\", StringType(), True),\n",
    "    StructField(\"Month\", StringType(), True),\n",
    "    StructField(\"Year\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Read data into DataFrame using schema\n",
    "try:\n",
    "    df = spark.read.csv(data_path, schema=schema, header=True)\n",
    "    df.show()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# If needed, select customer-related columns\n",
    "# df_customers = df.select(\"Contact\", \"Sex\", \"Age\", \"State\").distinct()\n",
    "\n",
    "# Show the DataFrame\n",
    "# df_customers.show()\n",
    "\n",
    "# Define PostgreSQL connection properties\n",
    "# pg_url = \"jdbc:postgresql://<host>:<port>/<database>\"\n",
    "# pg_properties = {\n",
    "#     \"user\": \"<username>\",\n",
    "#     \"password\": \"<password>\",\n",
    "#     \"driver\": \"org.postgresql.Driver\"\n",
    "# }\n",
    "\n",
    "# Write the DataFrame to PostgreSQL\n",
    "# df_customers.write.jdbc(url=pg_url, table=\"customers\", mode=\"overwrite\", properties=pg_properties)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select customer-related columns\n",
    "df_customers = df.select(\"Contact\", \"Sex\", \"Age\", \"State\").distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the DataFrame\n",
    "df_customers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_url = f'jdbc:postgresql://{postgres_host}/{postgres_dw_db}'\n",
    "jdbc_properties = {\n",
    "    'user': postgres_user,\n",
    "    'password': postgres_password,\n",
    "    'driver': 'org.postgresql.Driver',\n",
    "    'stringtype': 'unspecified'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame to PostgreSQL\n",
    "df_customers.write.jdbc(url=pg_url, table=\"customers\", mode=\"overwrite\", properties=pg_properties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
